{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "gcc (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "import detectron2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "# データセットがCOCOフォーマットなら以下のコードは次の3行で置き換えることができる。\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"fox_falco_train\", {}, \"/home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_train.json\", \"/home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_train\")\n",
    "register_coco_instances(\"fox_falco_val\", {}, \"/home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_val.json\", \"/home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 0x7f391c435c10>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3601it [13:54,  4.31it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obobo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from detectron2.modeling import build_model\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "import detectron2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.video_visualizer import VideoVisualizer\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.structures import Boxes\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # falco, fox, smallBF\n",
    "cfg.MODEL.WEIGHTS = \"/home/tappun/wip/output/model_final.pth\"\n",
    "cfg.MODEL.DEVICE='cuda:3'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESHOLD_TEST = 0.65\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.65\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.65\n",
    "cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = 0.65\n",
    "\n",
    "model = build_model(cfg)\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# dataset_dicts = DatasetCatalog.get(\"fox_falco_val_2\")\n",
    "\n",
    "#ワンチャンGPUで早くなるかも\n",
    "\n",
    "\n",
    "# video = cv2.VideoCapture('/home/tappun/short_fox_falco.mp4')\n",
    "video = cv2.VideoCapture('/home/tappun/ssbu_dataset/movie/fox_falco_smallBF1.mp4')\n",
    "\n",
    "print(video)\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Initialize video writer\n",
    "video_writer = cv2.VideoWriter('totemonagai2.mp4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
    "\n",
    "v = VideoVisualizer(MetadataCatalog.get(\"fox_falco_val_2\").set(thing_classes=[\"Falco\", \"Fox\", \"SmallBattleField\"]),ColorMode.IMAGE)\n",
    "\n",
    "\n",
    "def runOnVideo(video, maxFrames):\n",
    "    \"\"\" Runs the predictor on every frame in the video (unless maxFrames is given),\n",
    "    and returns the frame with the predictions drawn.\n",
    "    \"\"\"\n",
    "\n",
    "    readFrames = 0\n",
    "    while True:\n",
    "        \n",
    "        hasFrame, frame = video.read()\n",
    "        \n",
    "        if not hasFrame:\n",
    "            print(\"動画の読み込みに失敗\")\n",
    "            break\n",
    "\n",
    "        # Get prediction results for this frame\n",
    "        outputs = predictor(frame)\n",
    "\n",
    "        # Make sure the frame is colored\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw a visualization of the predictions using the video visualizer\n",
    "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
    "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        yield visualization\n",
    "\n",
    "        readFrames += 1\n",
    "        if readFrames > maxFrames:\n",
    "            print(\"obobo\")\n",
    "            break\n",
    "            \n",
    "# metadata=MetadataCatalog.get(\"fox_falco_val_2\").set(thing_classes=[\"Falco\", \"Fox\", \"PokemonStadium2\"]),\n",
    "\n",
    "# Create a cut-off for debugging\n",
    "num_frames = 3600\n",
    "\n",
    "# Enumerate the frames of the video\n",
    "for visualization in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
    "    # Write test image\n",
    "    cv2.imwrite('POSE detectron2.png', visualization)\n",
    "    # Write to video file\n",
    "    video_writer.write(visualization)\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "video_writer.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/10 22:24:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/10 22:24:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/10 22:24:39 d2.data.datasets.coco]: \u001b[0mLoaded 448 images in COCO format from /home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_train.json\n",
      "\u001b[32m[12/10 22:24:39 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 448 images left.\n",
      "\u001b[32m[12/10 22:24:39 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|   Falco    | 442          |    Fox     | 421          | SmallBattle.. | 416          |\n",
      "|            |              |            |              |               |              |\n",
      "|   total    | 1279         |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[12/10 22:24:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/10 22:24:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/10 22:24:39 d2.data.common]: \u001b[0mSerializing 448 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/10 22:24:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_721ade.pkl: 136MB [00:12, 10.5MB/s]                               \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (12, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fox_falco_train\n",
      "\u001b[32m[12/10 22:24:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tappun/.pyenv/versions/3.6.8/lib/python3.6/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:217: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/10 22:25:18 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 19  total_loss: 2.298  loss_cls: 1.329  loss_box_reg: 0.4149  loss_rpn_cls: 0.1989  loss_rpn_loc: 0.3387  time: 1.1729  data_time: 0.0117  lr: 4.9953e-06  max_mem: 0M\n",
      "\u001b[32m[12/10 22:25:42 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 39  total_loss: 2.105  loss_cls: 1.224  loss_box_reg: 0.4255  loss_rpn_cls: 0.1932  loss_rpn_loc: 0.2162  time: 1.1735  data_time: 0.0040  lr: 9.9902e-06  max_mem: 0M\n",
      "\u001b[32m[12/10 22:26:06 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 59  total_loss: 1.92  loss_cls: 1.058  loss_box_reg: 0.4295  loss_rpn_cls: 0.1862  loss_rpn_loc: 0.2603  time: 1.1769  data_time: 0.0038  lr: 1.4985e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:26:30 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 79  total_loss: 1.742  loss_cls: 0.8568  loss_box_reg: 0.4287  loss_rpn_cls: 0.1904  loss_rpn_loc: 0.2818  time: 1.1804  data_time: 0.0040  lr: 1.998e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:26:53 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 99  total_loss: 1.502  loss_cls: 0.663  loss_box_reg: 0.4044  loss_rpn_cls: 0.1726  loss_rpn_loc: 0.2451  time: 1.1787  data_time: 0.0038  lr: 2.4975e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:27:17 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 119  total_loss: 1.428  loss_cls: 0.5476  loss_box_reg: 0.4473  loss_rpn_cls: 0.1529  loss_rpn_loc: 0.2492  time: 1.1812  data_time: 0.0038  lr: 2.997e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:27:41 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 139  total_loss: 1.36  loss_cls: 0.5075  loss_box_reg: 0.493  loss_rpn_cls: 0.1469  loss_rpn_loc: 0.217  time: 1.1809  data_time: 0.0041  lr: 3.4965e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:28:04 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 159  total_loss: 1.175  loss_cls: 0.4406  loss_box_reg: 0.4362  loss_rpn_cls: 0.1286  loss_rpn_loc: 0.2067  time: 1.1801  data_time: 0.0038  lr: 3.996e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:28:28 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 179  total_loss: 1.195  loss_cls: 0.4123  loss_box_reg: 0.4573  loss_rpn_cls: 0.1492  loss_rpn_loc: 0.1777  time: 1.1808  data_time: 0.0039  lr: 4.4955e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:28:52 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 199  total_loss: 1.263  loss_cls: 0.4039  loss_box_reg: 0.4794  loss_rpn_cls: 0.1316  loss_rpn_loc: 0.201  time: 1.1816  data_time: 0.0039  lr: 4.995e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:29:16 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 219  total_loss: 1.273  loss_cls: 0.4071  loss_box_reg: 0.5255  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2142  time: 1.1830  data_time: 0.0035  lr: 5.4945e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:29:40 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 239  total_loss: 1.205  loss_cls: 0.3959  loss_box_reg: 0.5499  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.1832  time: 1.1841  data_time: 0.0040  lr: 5.994e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:30:03 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 259  total_loss: 1.176  loss_cls: 0.356  loss_box_reg: 0.535  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.175  time: 1.1847  data_time: 0.0037  lr: 6.4935e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:30:27 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 279  total_loss: 1.18  loss_cls: 0.3533  loss_box_reg: 0.5451  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.195  time: 1.1840  data_time: 0.0037  lr: 6.993e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:30:51 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 299  total_loss: 1.332  loss_cls: 0.3706  loss_box_reg: 0.5753  loss_rpn_cls: 0.09862  loss_rpn_loc: 0.2005  time: 1.1846  data_time: 0.0036  lr: 7.4925e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:31:15 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 319  total_loss: 1.191  loss_cls: 0.3339  loss_box_reg: 0.5497  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.2104  time: 1.1856  data_time: 0.0035  lr: 7.992e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:31:39 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 339  total_loss: 1.069  loss_cls: 0.2869  loss_box_reg: 0.5138  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.1592  time: 1.1862  data_time: 0.0038  lr: 8.4915e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:32:03 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 359  total_loss: 1.215  loss_cls: 0.3269  loss_box_reg: 0.6328  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1572  time: 1.1862  data_time: 0.0035  lr: 8.991e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:32:26 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 379  total_loss: 1.044  loss_cls: 0.2727  loss_box_reg: 0.534  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.1661  time: 1.1852  data_time: 0.0035  lr: 9.4905e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:32:50 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 399  total_loss: 1.203  loss_cls: 0.2946  loss_box_reg: 0.6662  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.2121  time: 1.1858  data_time: 0.0035  lr: 9.99e-05  max_mem: 0M\n",
      "\u001b[32m[12/10 22:33:14 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 419  total_loss: 1.156  loss_cls: 0.2709  loss_box_reg: 0.6281  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.197  time: 1.1864  data_time: 0.0036  lr: 0.0001049  max_mem: 0M\n",
      "\u001b[32m[12/10 22:33:38 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 439  total_loss: 1.226  loss_cls: 0.2848  loss_box_reg: 0.6267  loss_rpn_cls: 0.0752  loss_rpn_loc: 0.189  time: 1.1866  data_time: 0.0034  lr: 0.00010989  max_mem: 0M\n",
      "\u001b[32m[12/10 22:34:02 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 459  total_loss: 1.169  loss_cls: 0.2444  loss_box_reg: 0.6459  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.1688  time: 1.1864  data_time: 0.0036  lr: 0.00011489  max_mem: 0M\n",
      "\u001b[32m[12/10 22:34:25 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 479  total_loss: 1.098  loss_cls: 0.2398  loss_box_reg: 0.6111  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.1773  time: 1.1862  data_time: 0.0038  lr: 0.00011988  max_mem: 0M\n",
      "\u001b[32m[12/10 22:34:49 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 499  total_loss: 1.183  loss_cls: 0.2425  loss_box_reg: 0.6306  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.1929  time: 1.1865  data_time: 0.0036  lr: 0.00012488  max_mem: 0M\n",
      "\u001b[32m[12/10 22:35:13 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 519  total_loss: 1.06  loss_cls: 0.2124  loss_box_reg: 0.5829  loss_rpn_cls: 0.05348  loss_rpn_loc: 0.1752  time: 1.1866  data_time: 0.0036  lr: 0.00012987  max_mem: 0M\n",
      "\u001b[32m[12/10 22:35:37 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 539  total_loss: 1.038  loss_cls: 0.2063  loss_box_reg: 0.5653  loss_rpn_cls: 0.04301  loss_rpn_loc: 0.179  time: 1.1864  data_time: 0.0036  lr: 0.00013487  max_mem: 0M\n",
      "\u001b[32m[12/10 22:36:00 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 559  total_loss: 1.029  loss_cls: 0.1844  loss_box_reg: 0.5939  loss_rpn_cls: 0.05213  loss_rpn_loc: 0.1728  time: 1.1863  data_time: 0.0037  lr: 0.00013986  max_mem: 0M\n",
      "\u001b[32m[12/10 22:36:24 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 579  total_loss: 0.9808  loss_cls: 0.1857  loss_box_reg: 0.557  loss_rpn_cls: 0.05004  loss_rpn_loc: 0.1716  time: 1.1860  data_time: 0.0038  lr: 0.00014486  max_mem: 0M\n",
      "\u001b[32m[12/10 22:36:48 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 599  total_loss: 0.954  loss_cls: 0.192  loss_box_reg: 0.5596  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.1607  time: 1.1862  data_time: 0.0038  lr: 0.00014985  max_mem: 0M\n",
      "\u001b[32m[12/10 22:37:11 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 619  total_loss: 0.9765  loss_cls: 0.1938  loss_box_reg: 0.5486  loss_rpn_cls: 0.04406  loss_rpn_loc: 0.1524  time: 1.1861  data_time: 0.0037  lr: 0.00015485  max_mem: 0M\n",
      "\u001b[32m[12/10 22:37:35 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 639  total_loss: 0.9303  loss_cls: 0.1874  loss_box_reg: 0.5207  loss_rpn_cls: 0.03816  loss_rpn_loc: 0.1669  time: 1.1857  data_time: 0.0037  lr: 0.00015984  max_mem: 0M\n",
      "\u001b[32m[12/10 22:37:59 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 659  total_loss: 0.8585  loss_cls: 0.1648  loss_box_reg: 0.4615  loss_rpn_cls: 0.04283  loss_rpn_loc: 0.1709  time: 1.1858  data_time: 0.0034  lr: 0.00016484  max_mem: 0M\n",
      "\u001b[32m[12/10 22:38:23 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 679  total_loss: 0.7953  loss_cls: 0.1814  loss_box_reg: 0.4226  loss_rpn_cls: 0.0386  loss_rpn_loc: 0.154  time: 1.1860  data_time: 0.0041  lr: 0.00016983  max_mem: 0M\n",
      "\u001b[32m[12/10 22:38:49 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 699  total_loss: 0.8251  loss_cls: 0.1777  loss_box_reg: 0.4403  loss_rpn_cls: 0.04435  loss_rpn_loc: 0.1643  time: 1.1891  data_time: 0.0038  lr: 0.00017483  max_mem: 0M\n",
      "\u001b[32m[12/10 22:39:17 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 719  total_loss: 0.7088  loss_cls: 0.1586  loss_box_reg: 0.395  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.156  time: 1.1959  data_time: 0.0038  lr: 0.00017982  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/10 22:39:45 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 739  total_loss: 0.8341  loss_cls: 0.1913  loss_box_reg: 0.407  loss_rpn_cls: 0.04071  loss_rpn_loc: 0.1757  time: 1.2016  data_time: 0.0037  lr: 0.00018482  max_mem: 0M\n",
      "\u001b[32m[12/10 22:40:14 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 759  total_loss: 0.7712  loss_cls: 0.1531  loss_box_reg: 0.3891  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.1619  time: 1.2069  data_time: 0.0035  lr: 0.00018981  max_mem: 0M\n",
      "\u001b[32m[12/10 22:40:41 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 779  total_loss: 0.7252  loss_cls: 0.1421  loss_box_reg: 0.3815  loss_rpn_cls: 0.02896  loss_rpn_loc: 0.1584  time: 1.2114  data_time: 0.0035  lr: 0.00019481  max_mem: 0M\n",
      "\u001b[32m[12/10 22:41:07 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 799  total_loss: 0.6875  loss_cls: 0.1421  loss_box_reg: 0.3307  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.1624  time: 1.2128  data_time: 0.0038  lr: 0.0001998  max_mem: 0M\n",
      "\u001b[32m[12/10 22:41:31 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 819  total_loss: 0.7797  loss_cls: 0.1468  loss_box_reg: 0.3705  loss_rpn_cls: 0.0394  loss_rpn_loc: 0.1751  time: 1.2132  data_time: 0.0033  lr: 0.0002048  max_mem: 0M\n",
      "\u001b[32m[12/10 22:41:54 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 839  total_loss: 0.671  loss_cls: 0.1354  loss_box_reg: 0.3489  loss_rpn_cls: 0.03229  loss_rpn_loc: 0.1532  time: 1.2112  data_time: 0.0037  lr: 0.00020979  max_mem: 0M\n",
      "\u001b[32m[12/10 22:42:17 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 859  total_loss: 0.767  loss_cls: 0.1559  loss_box_reg: 0.3798  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.1694  time: 1.2104  data_time: 0.0035  lr: 0.00021479  max_mem: 0M\n",
      "\u001b[32m[12/10 22:42:41 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 879  total_loss: 0.7183  loss_cls: 0.1331  loss_box_reg: 0.3174  loss_rpn_cls: 0.03524  loss_rpn_loc: 0.1649  time: 1.2097  data_time: 0.0037  lr: 0.00021978  max_mem: 0M\n",
      "\u001b[32m[12/10 22:43:05 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 899  total_loss: 0.6533  loss_cls: 0.128  loss_box_reg: 0.3419  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.1556  time: 1.2097  data_time: 0.0042  lr: 0.00022478  max_mem: 0M\n",
      "\u001b[32m[12/10 22:43:29 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 919  total_loss: 0.6682  loss_cls: 0.1354  loss_box_reg: 0.3081  loss_rpn_cls: 0.03659  loss_rpn_loc: 0.1533  time: 1.2093  data_time: 0.0036  lr: 0.00022977  max_mem: 0M\n",
      "\u001b[32m[12/10 22:43:52 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 939  total_loss: 0.6203  loss_cls: 0.1248  loss_box_reg: 0.3253  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.1458  time: 1.2081  data_time: 0.0034  lr: 0.00023477  max_mem: 0M\n",
      "\u001b[32m[12/10 22:44:16 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 959  total_loss: 0.69  loss_cls: 0.1377  loss_box_reg: 0.3917  loss_rpn_cls: 0.02823  loss_rpn_loc: 0.1445  time: 1.2079  data_time: 0.0037  lr: 0.00023976  max_mem: 0M\n",
      "\u001b[32m[12/10 22:44:40 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 979  total_loss: 0.6735  loss_cls: 0.1498  loss_box_reg: 0.3718  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.1645  time: 1.2072  data_time: 0.0036  lr: 0.00024476  max_mem: 0M\n",
      "\u001b[32m[12/10 22:45:04 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.632  loss_cls: 0.1436  loss_box_reg: 0.3286  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.1522  time: 1.2066  data_time: 0.0036  lr: 0.00024975  max_mem: 0M\n",
      "\u001b[32m[12/10 22:45:04 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:20:04 (1.2066 s / it)\n",
      "\u001b[32m[12/10 22:45:04 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:06 (0:00:02 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/10 22:45:04 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/10 22:45:04 d2.data.datasets.coco]: \u001b[0mLoaded 50 images in COCO format from /home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_val.json\n",
      "\u001b[32m[12/10 22:45:04 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|   Falco    | 49           |    Fox     | 50           | SmallBattle.. | 50           |\n",
      "|            |              |            |              |               |              |\n",
      "|   total    | 149          |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[12/10 22:45:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/10 22:45:04 d2.data.common]: \u001b[0mSerializing 50 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/10 22:45:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/10 22:45:04 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_dataset(dataset_name, dataset_name_val):\n",
    "    cfg = get_cfg()\n",
    "    cfg.MODEL.DEVICE='cuda:3'\n",
    "#     cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (dataset_name,)\n",
    "    cfg.DATASETS.TEST = (dataset_name_val,)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    #cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\"\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\")\n",
    "    \n",
    "    #https://github.com/facebookresearch/detectron2/blob/master/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\n",
    "#     cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = 1000   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # faster, and good enough for this toy dataset (default: 512)\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # only has one class (ballon)\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESHOLD_TEST = 0.7\n",
    "\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    \n",
    "    print(dataset_name)\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Prepare the data set\n",
    "    dataset_name = \"fox_falco_train\"\n",
    "    dataset_name_val = \"fox_falco_val\"\n",
    "#     dicts_name   = \"balloon/train\"\n",
    "#     for d in [\"train\", \"val\"]:\n",
    "#         DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
    "#         MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
    "#     balloon_metadata = MetadataCatalog.get(dataset_name)\n",
    "#     # Verify the data set\n",
    "#     verify_dataset(dicts_name)\n",
    "\n",
    "    # train\n",
    "    train_dataset(dataset_name, dataset_name_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/10 23:06:44 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten()\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/10 23:06:44 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/10 23:06:44 d2.data.datasets.coco]: \u001b[0mLoaded 448 images in COCO format from /home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_train.json\n",
      "\u001b[32m[12/10 23:06:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 448 images left.\n",
      "\u001b[32m[12/10 23:06:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/10 23:06:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/10 23:06:44 d2.data.common]: \u001b[0mSerializing 448 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/10 23:06:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/10 23:06:45 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/10 23:06:45 d2.data.datasets.coco]: \u001b[0mLoaded 448 images in COCO format from /home/tappun/ssbu_dataset/20201126/fox_falco_smallBF_train.json\n",
      "\u001b[32m[12/10 23:06:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/10 23:06:45 d2.data.common]: \u001b[0mSerializing 448 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/10 23:06:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.24 MiB\n",
      "\u001b[32m[12/10 23:06:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 448 images\n",
      "\u001b[32m[12/10 23:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/448. 0.1911 s / img. ETA=0:02:58\n",
      "\u001b[32m[12/10 23:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 23/448. 0.2275 s / img. ETA=0:03:06\n",
      "\u001b[32m[12/10 23:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 35/448. 0.2229 s / img. ETA=0:02:59\n",
      "\u001b[32m[12/10 23:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 47/448. 0.2186 s / img. ETA=0:02:53\n",
      "\u001b[32m[12/10 23:07:10 d2.evaluation.evaluator]: \u001b[0mInference done 59/448. 0.2158 s / img. ETA=0:02:46\n",
      "\u001b[32m[12/10 23:07:15 d2.evaluation.evaluator]: \u001b[0mInference done 70/448. 0.2214 s / img. ETA=0:02:44\n",
      "\u001b[32m[12/10 23:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 82/448. 0.2213 s / img. ETA=0:02:39\n",
      "\u001b[32m[12/10 23:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 94/448. 0.2211 s / img. ETA=0:02:34\n",
      "\u001b[32m[12/10 23:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 106/448. 0.2213 s / img. ETA=0:02:28\n",
      "\u001b[32m[12/10 23:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 118/448. 0.2226 s / img. ETA=0:02:23\n",
      "\u001b[32m[12/10 23:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 130/448. 0.2244 s / img. ETA=0:02:18\n",
      "\u001b[32m[12/10 23:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 142/448. 0.2257 s / img. ETA=0:02:13\n",
      "\u001b[32m[12/10 23:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 154/448. 0.2252 s / img. ETA=0:02:08\n",
      "\u001b[32m[12/10 23:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 166/448. 0.2263 s / img. ETA=0:02:02\n",
      "\u001b[32m[12/10 23:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 177/448. 0.2281 s / img. ETA=0:01:58\n",
      "\u001b[32m[12/10 23:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 189/448. 0.2282 s / img. ETA=0:01:53\n",
      "\u001b[32m[12/10 23:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 200/448. 0.2302 s / img. ETA=0:01:49\n",
      "\u001b[32m[12/10 23:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 211/448. 0.2312 s / img. ETA=0:01:44\n",
      "\u001b[32m[12/10 23:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 223/448. 0.2313 s / img. ETA=0:01:39\n",
      "\u001b[32m[12/10 23:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 234/448. 0.2321 s / img. ETA=0:01:34\n",
      "\u001b[32m[12/10 23:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 246/448. 0.2306 s / img. ETA=0:01:29\n",
      "\u001b[32m[12/10 23:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 258/448. 0.2305 s / img. ETA=0:01:24\n",
      "\u001b[32m[12/10 23:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 269/448. 0.2312 s / img. ETA=0:01:19\n",
      "\u001b[32m[12/10 23:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 281/448. 0.2313 s / img. ETA=0:01:14\n",
      "\u001b[32m[12/10 23:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 292/448. 0.2319 s / img. ETA=0:01:09\n",
      "\u001b[32m[12/10 23:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 303/448. 0.2325 s / img. ETA=0:01:04\n",
      "\u001b[32m[12/10 23:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 314/448. 0.2330 s / img. ETA=0:00:59\n",
      "\u001b[32m[12/10 23:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 325/448. 0.2336 s / img. ETA=0:00:55\n",
      "\u001b[32m[12/10 23:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 337/448. 0.2337 s / img. ETA=0:00:49\n",
      "\u001b[32m[12/10 23:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 349/448. 0.2321 s / img. ETA=0:00:44\n",
      "\u001b[32m[12/10 23:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 361/448. 0.2312 s / img. ETA=0:00:38\n",
      "\u001b[32m[12/10 23:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 372/448. 0.2316 s / img. ETA=0:00:33\n",
      "\u001b[32m[12/10 23:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 383/448. 0.2319 s / img. ETA=0:00:29\n",
      "\u001b[32m[12/10 23:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 394/448. 0.2319 s / img. ETA=0:00:24\n",
      "\u001b[32m[12/10 23:09:46 d2.evaluation.evaluator]: \u001b[0mInference done 405/448. 0.2325 s / img. ETA=0:00:19\n",
      "\u001b[32m[12/10 23:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 416/448. 0.2334 s / img. ETA=0:00:14\n",
      "\u001b[32m[12/10 23:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 427/448. 0.2338 s / img. ETA=0:00:09\n",
      "\u001b[32m[12/10 23:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 438/448. 0.2343 s / img. ETA=0:00:04\n",
      "\u001b[32m[12/10 23:10:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:19.714147 (0.450822 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/10 23:10:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:43 (0.233997 s / img per device, on 1 devices)\n",
      "\u001b[32m[12/10 23:10:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/10 23:10:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[12/10 23:10:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      "\u001b[32m[12/10 23:10:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.013 | 0.068  | 0.001  |  nan  | 0.009 | 0.039 |\n",
      "\u001b[32m[12/10 23:10:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[12/10 23:10:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category         | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------------|:------|\n",
      "| Falco      | 0.010 | Fox        | 0.015 | SmallBattleField | 0.014 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 0.01286946355094265,\n",
       "               'AP50': 0.06786623391716579,\n",
       "               'AP75': 0.0013017121965733054,\n",
       "               'APs': nan,\n",
       "               'APm': 0.009210646667438307,\n",
       "               'APl': 0.038797082816075634,\n",
       "               'AP-Falco': 0.01023696579217589,\n",
       "               'AP-Fox': 0.014551115597108668,\n",
       "               'AP-SmallBattleField': 0.013820309263543384})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "dataset_name = \"fox_falco_train\"\n",
    "dataset_name_val = \"fox_falco_val\"\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE='cuda:3'\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (dataset_name,)\n",
    "cfg.DATASETS.TEST = (dataset_name_val,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # only has one class (ballon)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESHOLD_TEST = 0.7\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "evaluator = COCOEvaluator(dataset_name, (\"bbox\", ), False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, dataset_name)\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectron2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: detectron2 0.2.1+cu102\n",
      "Uninstalling detectron2-0.2.1+cu102:\n",
      "  Would remove:\n",
      "    /home/tappun/.pyenv/versions/3.6.8/lib/python3.6/site-packages/detectron2-0.2.1+cu102.dist-info/*\n",
      "    /home/tappun/.pyenv/versions/3.6.8/lib/python3.6/site-packages/detectron2/*\n",
      "Proceed (y/n)? "
     ]
    }
   ],
   "source": [
    "!pip uninstall detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6.8",
   "language": "python",
   "name": "python3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
